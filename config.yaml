task_name: physicaliqa
model: "roberta-large"
accumulate_grad_batches: 8
use_amp: false # Half precison only works best with volta architectures such as V100
max_epochs: 8
learning_rate: 2e-6
adam_epsilon: 10e-8
warmup_steps: 150
batch_size: 4
max_length: 128
formula: "goal -> sol1|sol2"
train_x: "data/piqa/train-knowledge.jsonl"
train_y: "data/piqa/train-labels.lst"
val_x: "data/piqa/valid-knowledge.jsonl"
val_y: "data/piqa/valid-labels.lst"
checkpoint: "/home/jupyter/ai2/outputs/2020-04-08/06-23-11/lightning_logs/version_0/checkpoints/_ckpt_epoch_4.ckpt"
k: 1
infusion: "concat"
